{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "363a00f1",
   "metadata": {},
   "source": [
    "# 自然语言处理 - 通用信息抽取\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173965ab",
   "metadata": {},
   "source": [
    "# 1. 实验介绍\n",
    "\n",
    "## 1.1 实验背景\n",
    "\n",
    "信息抽取旨在从非结构化自然语言文本中提取结构化知识，如实体、关系、事件等。\n",
    "\n",
    "本实验使用预训练好的关系抽取模型，进行针对性的微调，以此不同环境下的测试任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933447ef",
   "metadata": {},
   "source": [
    "## 1.2 实验要求\n",
    "\n",
    "a) 从数据集中选取合适的提示词和文本输入，\n",
    "\n",
    "b) 加载合适的预训练模型并进行针对性微调。\n",
    "\n",
    "c) 导出为 onnx 格式模型，并使用 TPU-MLIR 转化为 bmodel 模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744768e5",
   "metadata": {},
   "source": [
    "## 1.3 实验环境\n",
    "\n",
    "可以使用 Numpy 库进行相关数值运算，使用 PyTorch Transformers 库进行模型微调和加载预训练模型等。\n",
    "\n",
    "## 1.4 注意事项\n",
    "+ Python 与 Python Package 的使用方式，可在右侧 `API文档` 中查阅。\n",
    "+ 当右上角的『Python 3』长时间指示为运行中的时候，造成代码无法执行时，可以重新启动 Kernel 解决（左上角『Kernel』-『Restart Kernel』）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31964e69",
   "metadata": {},
   "source": [
    "## 1.5 参考资料\n",
    "\n",
    "Numpy：https://www.numpy.org/\n",
    "    \n",
    "Pytorch：https://pytorch.org/\n",
    "\n",
    "transformers： https://huggingface.co/docs/transformers/index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49b703",
   "metadata": {},
   "source": [
    "## 1.6 文件说明 \n",
    "\n",
    "```\n",
    "\n",
    "│   ├── checkpoint # 微调保存下来的模型 \n",
    "│   └── convert # 存放转换sh脚本文件和中间模型，将模型从onnx转化为bmodel文件的地方\n",
    "│       ├── mlir2bmodel.sh # 将模型从mlir转换为bmodel的脚本文件\n",
    "│       ├── onnx2mlir.sh # 将模型从onnx转换为mlir的脚本文件\n",
    "│   └── ernie.py # 定义ernie模型\n",
    "│   └── evaluate.py # 评估函数，提交后的推理方法就是依据evaluate.py文件\n",
    "│   └── export_model.py # 导出模型为onnx格式\n",
    "│   └── finetune.py # 模型微调训练\n",
    "│   └── main.ipynb # 主notebook\n",
    "│   └── model.py # 定义UIE模型\n",
    "│   └── tools.py # 工具函数\n",
    "│\n",
    "│   ├── datasets/6434c6eaaad2f9ce44d79682-momodel # 数据集和预训练模型权重\n",
    "│   └── data # 数据集\n",
    "│       ├── competition_train.txt  # 训练集txt，content为句子内容（第一个输入），promt为提示词（第二个输入），result_list为输出，包括输出文本和起始位置与终止位置\n",
    "│       ├── competition_valid.txt  # 验证集txt\n",
    "│   └── uie_nano_pytorch # 预训练nano模型\n",
    "│   └── uie_mini_pytorch # 预训练mini模型\n",
    "│   └── uie_micro_pytorch # 预训练micro模型\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc96dd1",
   "metadata": {},
   "source": [
    "# 2.实验内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48962c7",
   "metadata": {},
   "source": [
    "## 2.1 导入相关库，并进行参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f68e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 15:14:16.112010: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2023-05-16 15:14:16.112057: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# 导入相关库\n",
    "import argparse\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "from itertools import chain\n",
    "from typing import List, Union\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (BertTokenizer, PreTrainedModel,\n",
    "                          PreTrainedTokenizerBase, BertTokenizerFast)\n",
    "\n",
    "from tools import IEDataset, logger, tqdm, set_seed, SpanEvaluator, EarlyStopping, logging_redirect_tqdm, logger\n",
    "from model import UIE\n",
    "from evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b6cb9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复制模型权重到本地目录\n",
    "!cp -r datasets/6434c6eaaad2f9ce44d79682-momodel/uie_nano_pytorch ./\n",
    "\n",
    "# 这里仅用 nano 模型演示，也可使用 mini 或者 micro 模型\n",
    "# !cp -r datasets/6434c6eaaad2f9ce44d79682-momodel/uie_mini_pytorch ./\n",
    "# !cp -r datasets/6434c6eaaad2f9ce44d79682-momodel/uie_micro_pytorch ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718e57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置相关参数\n",
    "class args:\n",
    "    batch_size = 16\n",
    "    learning_rate = 1e-5\n",
    "    train_path = 'datasets/6434c6eaaad2f9ce44d79682-momodel/data/competition_train.txt'\n",
    "    dev_path = 'datasets/6434c6eaaad2f9ce44d79682-momodel/data/competition_valid.txt'\n",
    "    save_dir = 'uie_nano_pytorch'\n",
    "    max_seq_len = 512\n",
    "    num_epochs = 100\n",
    "    seed = 42\n",
    "    logging_steps = 100\n",
    "    valid_steps = 100\n",
    "    device = 'cpu'\n",
    "    model = 'uie_nano_pytorch'\n",
    "    max_model_num = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d062e6",
   "metadata": {},
   "source": [
    "## 2.2 导入预训练模型\n",
    "\n",
    "在下面的代码单元将实现以下功能：             \n",
    "- 设置随机数种子\n",
    "- 设置分词器，导入预训练模型\n",
    "- 设置是否使用 gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc965eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子\n",
    "set_seed(args.seed)\n",
    "show_bar = True\n",
    "\n",
    "# 设置分词器，导入预训练模型\n",
    "tokenizer = BertTokenizerFast.from_pretrained(args.model)\n",
    "model = UIE.from_pretrained(args.model)\n",
    "\n",
    "# 设置是否使用gpu\n",
    "if args.device == 'gpu':\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7391d852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UIE(\n",
       "  (encoder): ErnieModel(\n",
       "    (embeddings): ErnieEmbeddings(\n",
       "      (word_embeddings): Embedding(40000, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(2048, 312)\n",
       "      (token_type_embeddings): Embedding(4, 312)\n",
       "      (task_type_embeddings): Embedding(16, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ErnieEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ErnieLayer(\n",
       "          (attention): ErnieAttention(\n",
       "            (self): ErnieSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ErnieSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ErnieIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=1248, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ErnieOutput(\n",
       "            (dense): Linear(in_features=1248, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ErnieLayer(\n",
       "          (attention): ErnieAttention(\n",
       "            (self): ErnieSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ErnieSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ErnieIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=1248, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ErnieOutput(\n",
       "            (dense): Linear(in_features=1248, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ErnieLayer(\n",
       "          (attention): ErnieAttention(\n",
       "            (self): ErnieSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ErnieSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ErnieIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=1248, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ErnieOutput(\n",
       "            (dense): Linear(in_features=1248, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ErnieLayer(\n",
       "          (attention): ErnieAttention(\n",
       "            (self): ErnieSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ErnieSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ErnieIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=1248, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ErnieOutput(\n",
       "            (dense): Linear(in_features=1248, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): ErniePooler(\n",
       "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear_start): Linear(in_features=312, out_features=1, bias=True)\n",
       "  (linear_end): Linear(in_features=312, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看UIE模型结构\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cab7f8",
   "metadata": {},
   "source": [
    "## 2.3 构建训练数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06535aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入微调数据集和验证数据集\n",
    "train_ds = IEDataset(args.train_path, tokenizer=tokenizer,\n",
    "                     max_seq_len=args.max_seq_len)\n",
    "dev_ds = IEDataset(args.dev_path, tokenizer=tokenizer,\n",
    "                   max_seq_len=args.max_seq_len)\n",
    "train_data_loader = DataLoader(\n",
    "    train_ds, batch_size=args.batch_size, shuffle=True)\n",
    "dev_data_loader = DataLoader(\n",
    "    dev_ds, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7608bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   1,  417,  389,  ...,    0,    0,    0],\n",
      "        [   1,   21,  139,  ...,    0,    0,    0],\n",
      "        [   1,  593,  123,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,   31,  180,  ...,    0,    0,    0],\n",
      "        [   1,   59,  247,  ...,    0,    0,    0],\n",
      "        [   1,  450, 1140,  ...,    0,    0,    0]])\n",
      "torch.Size([16, 512])\n"
     ]
    }
   ],
   "source": [
    "# 查看loader中的一个batch\n",
    "input_ids, token_type_ids, att_mask, start_ids, end_ids = iter(train_data_loader).next()\n",
    "print(input_ids)\n",
    "print(input_ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf22ab",
   "metadata": {},
   "source": [
    "## 2.4 设置AdamW优化器，BCE损失以及评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e1ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    lr=args.learning_rate, params=model.parameters())\n",
    "\n",
    "criterion = torch.nn.functional.binary_cross_entropy\n",
    "metric = SpanEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35696b5f",
   "metadata": {},
   "source": [
    "## 2.5 训练前的参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7269ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练前的参数初始化置零\n",
    "loss_list = []\n",
    "loss_sum = 0\n",
    "loss_num = 0\n",
    "global_step = 0\n",
    "best_step = 0\n",
    "best_f1 = 0\n",
    "tic_train = time.time()\n",
    "epoch_iterator = range(1, args.num_epochs + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1e3302",
   "metadata": {},
   "source": [
    "## 2.6 正式训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5c290",
   "metadata": {},
   "source": [
    "由于在 notebook 中的内存限制，因此你需要使用 GPU Job 进行模型训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21a704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: \u001b[32m  0%\u001b[39m \u001b[34m░░░░░░░░░░\u001b[39m  \u001b[32m0/100 \u001b[31m?epoch/s\u001b[39m eta \u001b[36m?\u001b[39m\n",
      "Training Epoch 1: \u001b[32m  0%\u001b[39m \u001b[34m░░░░░░░░░░\u001b[39m  \u001b[32m0/19 \u001b[31m?batch/s\u001b[39m eta \u001b[36m?\u001b[39m\u001b[A\n",
      "Training: \u001b[32m  0%\u001b[39m \u001b[34m░░░░░░░░░░\u001b[39m  \u001b[32m0/100 \u001b[31m?epoch/s\u001b[39m eta \u001b[36m?\u001b[39m\u001b[39m eta \u001b[36m?\u001b[39m\u001b[A/home/jovyan/.virtualenvs/basenv/lib/python3.7/site-packages/transformers/modeling_utils.py:811: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n"
     ]
    }
   ],
   "source": [
    "if show_bar:\n",
    "    train_postfix_info = {'loss': 'unknown'}\n",
    "    epoch_iterator = tqdm(\n",
    "        epoch_iterator, desc='Training', unit='epoch')\n",
    "\n",
    "# 正式开始训练\n",
    "for epoch in epoch_iterator:\n",
    "    train_data_iterator = train_data_loader\n",
    "    if show_bar:\n",
    "        train_data_iterator = tqdm(train_data_iterator,\n",
    "                                   desc=f'Training Epoch {epoch}', unit='batch')\n",
    "        train_data_iterator.set_postfix(train_postfix_info)\n",
    "\n",
    "    # 迭代训练集\n",
    "    for batch in train_data_iterator:\n",
    "        if show_bar:\n",
    "            epoch_iterator.refresh()\n",
    "\n",
    "        # 取出每一个batch的输入输出\n",
    "        input_ids, token_type_ids, att_mask, start_ids, end_ids = batch\n",
    "\n",
    "        # 如果使用gpu，则将其放入到cuda中\n",
    "        if args.device == 'gpu':\n",
    "            input_ids = input_ids.cuda()\n",
    "            token_type_ids = token_type_ids.cuda()\n",
    "            att_mask = att_mask.cuda()\n",
    "            start_ids = start_ids.cuda()\n",
    "            end_ids = end_ids.cuda()\n",
    "\n",
    "        # 模型推理预测\n",
    "        outputs = model(input_ids=input_ids,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        attention_mask=att_mask)\n",
    "        start_prob, end_prob = outputs[0], outputs[1]\n",
    "\n",
    "        # 进行反向传播与loss计算\n",
    "        start_ids = start_ids.type(torch.float32)\n",
    "        end_ids = end_ids.type(torch.float32)\n",
    "        loss_start = criterion(start_prob, start_ids)\n",
    "        loss_end = criterion(end_prob, end_ids)\n",
    "        loss = (loss_start + loss_end) / 2.0\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss_list.append(float(loss))\n",
    "        loss_sum += float(loss)\n",
    "        loss_num += 1\n",
    "\n",
    "        if show_bar:\n",
    "            loss_avg = loss_sum / loss_num\n",
    "            train_postfix_info.update({\n",
    "                'loss': f'{loss_avg:.5f}'\n",
    "            })\n",
    "            train_data_iterator.set_postfix(train_postfix_info)\n",
    "\n",
    "        global_step += 1\n",
    "        if global_step % args.logging_steps == 0:\n",
    "            time_diff = time.time() - tic_train\n",
    "            loss_avg = loss_sum / loss_num\n",
    "\n",
    "            if show_bar:\n",
    "                with logging_redirect_tqdm([logger.logger]):\n",
    "                    logger.info(\n",
    "                        \"global step %d, epoch: %d, loss: %.5f, speed: %.2f step/s\"\n",
    "                        % (global_step, epoch, loss_avg,\n",
    "                           args.logging_steps / time_diff))\n",
    "            else:\n",
    "                logger.info(\n",
    "                    \"global step %d, epoch: %d, loss: %.5f, speed: %.2f step/s\"\n",
    "                    % (global_step, epoch, loss_avg,\n",
    "                       args.logging_steps / time_diff))\n",
    "            tic_train = time.time()\n",
    "\n",
    "        # 迭代到一定次数后，对验证集进行评估\n",
    "        if global_step % args.valid_steps == 0:\n",
    "            save_dir = os.path.join(\n",
    "                args.save_dir, \"model_%d\" % global_step)\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            model_to_save = model\n",
    "            model_to_save.save_pretrained(save_dir)\n",
    "            tokenizer.save_pretrained(save_dir)\n",
    "            if args.max_model_num:\n",
    "                model_to_delete = global_step-args.max_model_num*args.valid_steps\n",
    "                model_to_delete_path = os.path.join(\n",
    "                    args.save_dir, \"model_%d\" % model_to_delete)\n",
    "                if model_to_delete > 0 and os.path.exists(model_to_delete_path):\n",
    "                    shutil.rmtree(model_to_delete_path)\n",
    "\n",
    "            dev_loss_avg, precision, recall, f1 = evaluate(\n",
    "                model, metric, data_loader=dev_data_loader, device=args.device, loss_fn=criterion)\n",
    "\n",
    "            if show_bar:\n",
    "                train_postfix_info.update({\n",
    "                    'F1': f'{f1:.3f}',\n",
    "                    'dev loss': f'{dev_loss_avg:.5f}'\n",
    "                })\n",
    "                train_data_iterator.set_postfix(train_postfix_info)\n",
    "                with logging_redirect_tqdm([logger.logger]):\n",
    "                    logger.info(\"Evaluation precision: %.5f, recall: %.5f, F1: %.5f, dev loss: %.5f\"\n",
    "                                % (precision, recall, f1, dev_loss_avg))\n",
    "            else:\n",
    "                logger.info(\"Evaluation precision: %.5f, recall: %.5f, F1: %.5f, dev loss: %.5f\"\n",
    "                            % (precision, recall, f1, dev_loss_avg))\n",
    "\n",
    "            # 如果模型F1指标最优，那么保存该模型\n",
    "            # Save model which has best F1\n",
    "            if f1 > best_f1:\n",
    "                if show_bar:\n",
    "                    with logging_redirect_tqdm([logger.logger]):\n",
    "                        logger.info(\n",
    "                            f\"best F1 performence has been updated: {best_f1:.5f} --> {f1:.5f}\"\n",
    "                        )\n",
    "                else:\n",
    "                    logger.info(\n",
    "                        f\"best F1 performence has been updated: {best_f1:.5f} --> {f1:.5f}\"\n",
    "                    )\n",
    "                best_f1 = f1\n",
    "                save_dir = os.path.join(args.save_dir, \"model_best\")\n",
    "                model_to_save = model\n",
    "                model_to_save.save_pretrained(save_dir)\n",
    "                tokenizer.save_pretrained(save_dir)\n",
    "            tic_train = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b500e",
   "metadata": {},
   "source": [
    "# 3 模型评估和迁移"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b20838",
   "metadata": {},
   "source": [
    "## 3.1 导出模型\n",
    "将模型从pth格式导出为onnx格式，再将模型从onnx格式导出为bmodel格式\n",
    "\n",
    "由于我们最终的模型需要在算能的BM1684X芯片上运行，BM1684X需要接受bmodel文件来运行指令集\n",
    "我们使用算能提供的[TPU-MLIR](https://tpumlir.org/docs/quick_start/index.html)\n",
    "\n",
    "具体步骤为\n",
    "1. 使用torch.onnx.export导出onnx格式文件\n",
    "2. 使用model_transform.py命令，将onnx文件转换为mlir中间文件\n",
    "3. 使用model_deploy.py命令，将mlir中间文件转化为bmodel文件\n",
    "\n",
    "关于TPU-MLIR的更多介绍，model_transform model_deploy命令的传入参数说明，请参考\n",
    "https://tpumlir.org/docs/quick_start/index.html\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4499894",
   "metadata": {},
   "source": [
    "## 3.2 torch转onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab43d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先将模型导出为onnx格式\n",
    "def export_onnx(output_path: Union[Path, str], tokenizer: PreTrainedTokenizerBase, model: PreTrainedModel, device: torch.device, input_names: List[str], output_names: List[str]):\n",
    "    with torch.no_grad():\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        model.config.return_dict = True\n",
    "        model.config.use_cache = False\n",
    "\n",
    "        output_path = Path(output_path)\n",
    "\n",
    "        # Create folder\n",
    "        if not output_path.exists():\n",
    "            output_path.mkdir(parents=True)\n",
    "        save_path = output_path / \"inference.onnx\"\n",
    "\n",
    "        dynamic_axes = {name: {0: 'batch', 1: 'sequence'}\n",
    "                        for name in chain(input_names, output_names)}\n",
    "\n",
    "        # Generate dummy input\n",
    "        batch_size = 2\n",
    "        seq_length = 6\n",
    "        dummy_input = [\" \".join([tokenizer.unk_token])\n",
    "                       * seq_length] * batch_size\n",
    "        inputs = dict(tokenizer(dummy_input, return_tensors=\"pt\"))\n",
    "\n",
    "        if save_path.exists():\n",
    "            logger.warning(f'Overwrite model {save_path.as_posix()}')\n",
    "            save_path.unlink()\n",
    "\n",
    "        torch.onnx.export(model,\n",
    "                          (inputs,),\n",
    "                          save_path,\n",
    "                          input_names=input_names,\n",
    "                          output_names=output_names,\n",
    "                          dynamic_axes=dynamic_axes,\n",
    "                          do_constant_folding=True,\n",
    "                          opset_version=11\n",
    "                          )\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        logger.error(f'Export Failed!')\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60d89933",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = [\n",
    "    'input_ids',\n",
    "    'token_type_ids',\n",
    "    'attention_mask',\n",
    "]\n",
    "output_names = [\n",
    "    'start_prob',\n",
    "    'end_prob'\n",
    "]\n",
    "output_path = 'uie_nano_pytorch'\n",
    "model_path = 'uie_nano_pytorch'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = UIE.from_pretrained(model_path)\n",
    "device = torch.device('cpu')\n",
    "\n",
    "save_path = export_onnx(output_path, tokenizer, model, device, input_names, output_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958cc427",
   "metadata": {},
   "source": [
    "## 3.3 onnx转bmodel\n",
    "打开一个命令行终端，切换到convert目录下\n",
    "\n",
    "1.   \n",
    "\n",
    "```bash\n",
    "cd convert\n",
    "```\n",
    "\n",
    "2.   \n",
    "\n",
    "```bash\n",
    "cp ../uie_nano_pytorch/inference.onnx ./ \n",
    "```\n",
    "\n",
    "3. 使用 model_transform.py 命令，将 onnx 文件转换为 mlir 中间文件\n",
    "在命令行输入：\n",
    "\n",
    "```bash\n",
    "sh onnx2mlir.sh\n",
    "```\n",
    "\n",
    "4. 使用 model_deploy.py 命令，将 mlir 文件转换为 mlir 中间文件\n",
    "在命令行输入：\n",
    "\n",
    "```bash\n",
    "sh mlir2bmodel.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc7553b",
   "metadata": {},
   "source": [
    "## 3.4 提交代码示例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126e0b1",
   "metadata": {},
   "source": [
    "提交代码中，不需要撰写评估函数，但是需要提供原始的 `torch` 模型路径和转换后的 `bmodel` 模型路径。以 `uie-nano` 为例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad721e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel_name = 'convert/uie-nano.bmodel'\n",
    "model_name = 'uie_nano_pytorch'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3743ac92",
   "metadata": {},
   "source": [
    "# 4. 提交内容清单\n",
    "\n",
    "- 转换的 bmodel 模型文件\n",
    "- 包含`bmodel_name`和`model_name`的 main.py 文件\n",
    "- 其他相关模型权重及文件\n",
    "\n",
    "**注：模型测试过程不使用 bmodel 文件，使用原始模型进行推理，推理设备为 CPU**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
